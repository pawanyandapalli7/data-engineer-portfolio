# Spark / PySpark Data Processing

This folder demonstrates common Spark patterns used in
large-scale data engineering pipelines.

## What This Covers
- Deduplication and CDC-style transformations
- Data enrichment joins
- Partitioning and performance considerations
- Data quality validation

These patterns are commonly implemented using AWS Glue or Spark on EMR.

### ⚡ Spark / PySpark Processing

- Implemented Spark transformations for deduplication and enrichment
- Applied window functions for CDC-style processing
- Addressed performance via partitioning and data layout

➡️ See code: `03_spark_pyspark`

